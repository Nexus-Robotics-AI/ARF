# 🔥 ARF 模块开发参考文档：遥操作模块 (Teleoperation)

> 🎯 **角色定位:** ARF的"虚拟驾驶舱"与"专家示教器" - 实现高保真远程临场、人机协同与失败学习。
>
> 📦 **模块代号:** `arf-edge-teleop`
>
> ⚡ **所属:** ARF 边缘平台 (Edge Plane)

## 📋 1. 核心职责与设计理念

### 🎯 核心使命 (Core Mission)

作为ARF的“沉浸式协同界面”和“专家示教器”，遥操作模块的核心使命是**建立一条从人类操作员到机器人本体的、高保真、低延迟、双向沉浸式的通信链路**。它不仅是机器人的“驾驶”工具，更是连接自主智能(`DIL`)与人类智慧的桥梁，是实现**失败学习**、**人机协同**闭环和**远程精细操作**的关键。

主要应用场景包括：

- **✍️ 高保真示教数据采集:** 操作员通过VR等设备演示复杂任务，系统记录下高质量的、可用于模仿学习(IL)的完整数据流。
- **🤝 人机协同与AR辅助:** 人类操作员与`DIL`的自主策略协同工作。人类负责战略决策，AI通过**增强现实(AR)指引**提供战术辅助，极大降低操作难度。
- **🚨 远程故障干预与修正:** 当`DIL`的自主任务失败时，无缝切换到遥操作模式，由人类专家进行修正。此修正过程本身就是宝贵的“失败数据”。
- **🔬 沉浸式远程调试与力反馈操作:** 开发者通过双目视频和**双向力反馈**，获得亲临现场(Telepresence)并“感同身受”的体验，进行远程调试或完成精细的物理交互任务。

### 🏗️ 核心架构：“共享自主”下的模式切换 (Mode Switching under Shared Autonomy)

我们的遥操作架构不再是一个孤立的模块，而是**`DIL`决策智能层的一个可切换的“超级策略”**。

- **模式管理器 (Mode Manager):** `DIL`内部包含一个模式管理器。正常情况下，机器人处于`AUTONOMOUS`（自主）模式。当满足特定条件（如收到App指令、或自主任务失败）时，`DIL`会切换到`TELEOPERATION`（遥操作）模式。
- **遥操作服务 (`teleop-service`):** 在`TELEOPERATION`模式下，此服务被激活。它负责处理与操作员终端（VR/Web）的通信，并将操作员指令**直接或经过补偿算法处理后**，发送给`HAL`和`RTS`。
- **在线/离线学习接口:** `teleop-service`在执行操作员指令的同时，会将这些“专家数据”发布到`DMS`的特定主题上，供**在线残差学习模块**或**离线训练模块**使用。

### ⚖️ 设计原则 (Design Principles)

- **⚡ 沉浸感与低延迟优先 (Immersion & Low Latency First):** 端到端的控制与视频延迟是首要优化目标。
- **🛡️ 安全性是底线 (Safety is the Bottom Line):** 必须通过“虚拟臂”、碰撞检测和冗余安全机制，确保操作员的任何指令都不会危害机器人或环境。
- **🤝 协同而非取代 (Collaboration over Replacement):** 遥操作应被设计为可以与自主智能协同工作的模式，而不是简单的互斥关系。
- **🧩 数据为王 (Data is King):** 遥操作过程中的每一次交互，都应被视为可用于改进自主模型的宝贵数据。
- **🖐️ 触觉共通 (Haptic Correspondence):** 追求操作员的“感受”与机器人末端的“感受”一致，实现高保真的力觉交互。

## 📝 2. 核心需求 (Core Requirements)

| **ID** | **需求描述**                                | **验收标准**                                                 | **优先级**     |
| ------ | ------------------------------------------- | ------------------------------------------------------------ | -------------- |
| **T1** | **高保真控制 (High-Fidelity Control)**      | 必须实现精细的操作映射，包括坐标标定、低通滤波、离合器、死区和变速器等功能。 | **最高**       |
| **T2** | **主动安全保障 (Proactive Safety)**         | 必须实现基于“虚拟臂”的碰撞、奇异点、关节极限的提前预警（视觉与触觉反馈）。必须包含急停和看门狗机制。 | **最高**       |
| **T3** | **失败学习闭环 (Failure Learning Loop)**    | 当`DIL`自主任务失败时，系统必须能无缝切换到遥操作模式，并完整记录操作员的修正过程作为训练数据。 | **最高**       |
| **T4** | **沉浸式反馈 (Immersive Feedback)**         | 必须支持将双目视频流(Stereo Vision)实时传输到VR端，并支持在VR端渲染与真实机器人同步的3D模型。 | **高**         |
| **T5** | **多VR设备适配 (Multi-VR Support)**         | 至少需要支持Meta Quest 3和Pico 4两款主流VR设备。             | **高**         |
| **T6** | **在线补偿/协同算法 (Online Compensation)** | 必须提供接口，允许接入一个“在线残差模块”，该模块可以根据实时力反馈等信息，对VLA模型的宏观动作进行微调。 | **高**         |
| **T7** | **双向力反馈**                              | **[V1.1+ 新增]** 必须支持将机器人末端的力/扭矩传感器数据回传，并驱动操作员侧的力反馈设备。 | **高 (V1.1+)** |
| **T8** | **增强现实(AR)辅助**                        | **[V1.1+ 新增]** 必须支持在操作员的视频画面上，叠加由`DIL`/`ACR`生成的AR指引信息（如目标框、推荐轨迹）。 | **中 (V1.1+)** |

## ⚙️ 3. 关键功能与子模块架构

### 🧠 3.1 遥操作服务 (`teleop-service`)

**机器人端的协同智能网关**：这是运行在机器人上的核心服务。

- **人机映射与标定 (Calibration & Mapping):**
  - 实现三点标定法，计算操作员空间（VR）与机器人空间（World）之间的坐标变换矩阵。
  - 实现“离合器”、低通滤波、变速器等控制增强算法。
- **安全与虚拟臂 (Safety & Virtual Arm):**
  - 在内部实时运行一个IK求解器（如TRAC-IK）来驱动一个“虚拟臂”模型。
  - 将期望的运动指令发送给MoveIt进行碰撞、奇异点和关节极限检测。
  - 根据MoveIt的反馈，更新虚拟臂的颜色（如红色表示危险）并触发手柄震动。
- **模式切换接口:** 提供gRPC接口，供`DIL`调用以激活或停用遥操作模式。
- **数据发布器:** 将操作员的原始指令、经过处理的指令以及机器人的反馈，全部以标准化格式发布到`DMS`。
- **力反馈渲染器 (Haptic Renderer):**
  - **职责:** 这是`teleop-service`内部的新组件。它订阅来自`HAL`的力/扭矩传感器数据流，经过处理（如滤波、缩放）后，将其编码并通过低延迟通道发送给遥操作前端，以驱动力反馈设备。
- **AR叠加合成器 (AR Overlay Compositor):
  AR 叠加合成器 (AR Overlay Compositor):**
  - **职责:** 接收来自`DIL`或`ACR`的AR元数据（如“在(x,y)坐标处绘制一个高亮框”），并将其与实时视频流进行合成，或直接将元数据转发给前端，由前端进行渲染。

### 💻 3.2 遥操作前端 (VR Application)

**操作员的沉浸式驾驶舱**：一个运行在VR头显（如Quest 3, Pico 4）中的Unity/Unreal应用。

- **双目视频渲染:** 接收并渲染来自ZEDM等双目相机的两条视频流，提供立体视觉。
- **虚拟臂渲染:** 实时渲染“虚拟臂”模型，其颜色和状态会根据后端的安全检测结果而变化，为操作员提供即时预警。
- **3D场景重建(可选):** 接收实时点云数据，在VR中重建周围环境，增强沉浸感。
- **UI与教学:** 提供虚拟按钮（如急停、开始/停止记录），并通过引导教程教会用户“离合”等核心功能。
- **力反馈执行器:** **[V1.1+ 新增]** 接收来自后端的力反馈信号，并驱动本地连接的VR手柄或专用设备产生相应的力或震动。
- **AR信息渲染:** **[V1.1+ 新增]** 在视频画面之上，根据后端发来的元数据渲染AR指引信息。

### 🤖 3.3 与ACR/DIL的交互

**协同工作**：遥操作不再是孤立的，而是与智能层紧密耦合。

- **失败切换流程:** `DIL`的`FailureDetectorNode`检测到任务失败 -> 调用`teleop-service`的`ActivateInterventionMode` RPC -> `teleop-service`接管控制权，并开始记录专家数据。
- **在线残差学习流程:**
  1. `DIL`中的VLA模型输出一个**宏观动作** `a_vla`。
  2. 一个独立的`ACR`容器（**残差网络**），订阅`a_vla`和实时的力/扭矩传感器数据。
  3. `残差网络`计算出一个微小的**补偿动作** `Δa`。
  4. 最终指令 `a_final = a_vla + Δa` 被发送给`HAL`。
  5. 在遥操作示教时，`Δa`就是“人类专家的微操”与“VLA模型的原始想法”之间的差值，用于训练残差网络。

## 🔗 4. 接口设计与数据流

`teleop.proto`需要被大幅扩展，以支持模式切换和更丰富的协同数据。

### 📥 输入数据流

| **数据源**              | **数据类型**            | **优先级** | **延迟要求** | **示例场景**               |
| ----------------------- | ----------------------- | ---------- | ------------ | -------------------------- |
| **VR控制器**            | `6DoF Pose`             | `CRITICAL` | `< 16ms`     | VR手柄移动                 |
| **DIL决策层**           | `ActivateTeleopRequest` | `CRITICAL` | `< 50ms`     | 自主任务失败，请求人工介入 |
| **ACR (残差网络)**      | `ActionResidual Δa`     | `HIGH`     | `< 20ms`     | 对VLA动作进行在线微调      |
| **HAL (力/扭矩传感器)** | `Wrench` (力/扭矩数据)  | `CRITICAL` | `< 10ms`     | 机器人末端接触物体         |

### 📤 输出数据流

| **目标模块**       | **数据类型**                                                 | **保证** | **性能指标**          |
| ------------------ | ------------------------------------------------------------ | -------- | --------------------- |
| **HAL/RTS**        | `MotorCommand`                                               | 低延迟   | 端到端控制延迟 < 50ms |
| **DMS (用于学习)** | `ExpertTrajectoryData`                                       | 可靠记录 | 数据100%无损          |
| **VR端**           | 双目视频流, `VirtualArmState，`**`HapticFeedback`**, **`AR_Overlay_Metadata`** | 实时     | 视频延迟 < 150ms      |
| **力反馈设备**     | `Force/Torque Command`                                       | 低延迟   | 驱动力反馈设备        |

### 🧬 核心API草案 (`teleop.proto` V1.1)

```protobuf
// protos/arf/edge/v1/teleop.proto
syntax = "proto3";
package arf.edge.v1;

// ... import statements ...

// 遥操作服务
service TeleoperationService {
  // DIL调用此方法来激活/停用遥操作模式
  rpc SetMode(SetTeleopModeRequest) returns (SetTeleopModeResponse);
  
  // VR/Web前端用于建立双向通信的主通道
  rpc CommandStream(stream OperatorInput) returns (stream RobotFeedback);
}

message SetTeleopModeRequest {
    bool activate = 1;
    string reason = 2; // e.g., "AUTONOMOUS_FAILURE", "USER_REQUEST"
}
message SetTeleopModeResponse {
    bool success = 1;
}

// 来自操作员的输入流
message OperatorInputStream {
    oneof input_data {
        // VR手柄姿态、按钮状态等
        ControllerState controller_state = 1;
        // 其他UI事件
        UIEvent ui_event = 2;
    }
}

// 回传给操作员的反馈流
message RobotFeedbackStream {
    oneof feedback_data {
        // 视频流 (用于FPV)
        arf.v1.ImageFrame video_stream = 1; 
        // 机器人本体状态 (电量、速度等)
        RobotState robot_state = 2;
        // [V1.1 新增] 力反馈信号
        HapticFeedback haptic_feedback = 3; 
        // [V1.1 新增] AR叠加层元数据
        AROverlayMetadata ar_metadata = 4;
    }
}

// 力反馈信号
message HapticFeedback {
    arf.v1.Wrench wrench = 1; // 机器人末端感受到的力与力矩
    // ... 其他震动、纹理等信息
}

// AR叠加层元数据
message AROverlayMetadata {
    // ... 定义如高亮框、路径线、文本标签等AR元素
}
```

## 🛠️ 5. 技术栈与开发环境

### 💻 核心技术栈

| **技术领域**     | **选型**                                                 | **版本要求**             | **用途说明**                                          |
| ---------------- | -------------------------------------------------------- | ------------------------ | ----------------------------------------------------- |
| **核心服务语言** | **C++ / Python**                                         | `C++17+`, `Python 3.10+` | C++用于高性能的WebRTC和IK，Python用于快速实现上层逻辑 |
| **VR开发**       | **Unity / Unreal Engine**                                | 最新稳定版               | 构建沉浸式前端应用                                    |
| **WebRTC库**     | **Google `libwebrtc` (C++)**, **Unity Render Streaming** | 最新稳定版               | 实现低延迟音视频和数据传输                            |
| **运动规划**     | **MoveIt 2**                                             | `Humble+`                | 用于碰撞检测和IK解算                                  |
| **IK求解器**     | **TRAC-IK / BioIK**                                      | 最新稳定版               | 解决复杂的逆运动学问题                                |

## 🔧 6. 开发实施细节

### 🏗️ 6.1 项目结构 V1

```
services/edge-plane/teleop-service/  # 遥操作后端服务 (C++/Python)
├── src/
│   ├── main.cpp
│   ├── webrtc_server.cpp
│   ├── safety_supervisor.cpp    # 包含虚拟臂和MoveIt交互
│   └── calibration.cpp          # 标定逻辑
└── ...

application/vr-teleop-client/        # VR前端应用 (Unity)
├── Assets/
│   ├── Scripts/
│   │   └── WebRTCClient.cs
│   │   └── InputHandler.cs
│   └── Scenes/
└── ...
```

### 🧪 6.2 测试与验证策略



- **标定精度测试:** 使用外部测量设备（如OptiTrack）验证标定后的坐标映射误差。
- **安全功能测试:** 编写测试用例，在仿真中故意让虚拟臂接近碰撞或奇异点，验证VR端的预警和震动反馈是否被正确触发。
- **失败学习闭环测试:** 搭建一个完整的“VLA失败->人工修正->数据记录”的端到端测试，验证记录下的数据格式和内容是否符合离线训练的要求。

------



## 🚀 7. 开发任务 (Getting Started)





#### **第一阶段：高保真基础控制 (High-Fidelity Basic Control)**



- **任务1：实现三点标定流程**
  - **交付物:** 一个引导用户完成标定的VR/机器人端程序，能正确计算并应用坐标变换矩阵。
- **任务2：实现基础控制算法**
  - **交付物:** 在遥操作服务中实现“离合器”、低通滤波、死区和变速器等核心控制逻辑。
- **任务3：打通与真实机械臂的控制**
  - **交付物:** 能够通过VR手柄，流畅、稳定地控制真实机械臂的末端。



#### **第二阶段：主动安全与虚拟臂 (Proactive Safety & Virtual Arm)**



- **任务1：集成MoveIt与IK求解器**
  - **交付物:** `teleop-service`能够根据手柄姿态，使用TRAC-IK/BioIK实时解算关节角度。
- **任务2：实现虚拟臂与安全预警**
  - **交付物:** VR端能够实时渲染一个与期望动作同步的“虚拟臂”。当MoveIt检测到碰撞/奇异点风险时，虚拟臂会变色，同时VR手柄会震动。
- **任务3：实现安全机制**
  - **交付物:** 急停按钮、看门狗和最大移动差值限制功能开发完成并通过测试。



#### **第三阶段：失败学习与人机协同 (Failure Learning & Collaboration)**



- **任务1：实现`DIL`的模式切换**
  - **交付物:** `DIL`服务能够在一个自主任务失败时，自动调用`teleop-service`的RPC，激活遥操作模式。
- **任务2：实现专家数据记录**
  - **交付物:** 在遥操作修正过程中，`DMS`能够完整记录下时间戳对齐的`场景数据`、`失败指令`和`专家修正轨迹`。
- **任务3：开发在线残差学习模块原型**
  - **交付物:** 一个独立的`ACR`容器，能加载一个预训练的MLP网络，并根据模拟的传感器输入和VLA动作，输出一个补偿值。



#### **第四阶段：沉浸感与易用性 (Immersion & Usability)**



- **任务1：实现双目视频传输**
  - **交付物:** 能够将ZEDM等双目相机的视频流，通过WebRTC传输并在VR端渲染，提供立体视觉。
- **任务2：实现3D模型同步**
  - **交付物:** VR端能够渲染一个与真实机器人关节状态同步的3D模型。
- **任务3：完善用户引导**
  - **交付物:** 开发一套自动化的标定引导和新用户功能教学流程。
- **任务4：系统集成与端到端测试**
  - **交付物:** 完成“指向交互与失败学习闭环”的完整演示，并提交测试报告。

#### **第五阶段及以后：迈向沉浸式协同触觉界面 (Towards Immersive Haptic Interface)**



*此部分为V1.1及后续版本规划，旨在实现更高阶的人机交互。*

- **任务5.1: 实现双向力反馈闭环**
  - **交付物:** 与`HAL`团队协作，集成力/扭矩传感器和力反馈手柄。在一个测试场景中，当操作员控制虚拟臂按压一个虚拟弹簧时，能清晰地感受到与按压深度成正比的力反馈。
- **任务5.2: 开发AR辅助操作原型**
  - **交付物:** `DIL`能在一个抓取任务中，生成建议抓取目标的“高亮框”AR元数据。遥操作前端能成功接收并将其叠加在视频画面上，辅助操作员定位。
- **任务5.3: 力反馈遥操作稳定性测试**
  - **交付物:** 提交一份测试报告，分析在不同网络延迟和抖动下，力反馈遥操作系统的稳定性，并确定可用的操作边界。
- **任务5.4: 完善协同操作工作流**
  - **交付物:** 设计并实现一个完整的“共享自主”任务流程：操作员通过AR指引选择目标，机器人自主规划并执行大部分动作，在需要精细力控制的关键步骤（如插拔插头），无缝切换到力反馈遥操作模式。