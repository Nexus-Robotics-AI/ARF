# 🔥 ARF 模块开发参考文档：训练模块 (Training)

> 🎯 **角色定位:** ARF的"AI模型工厂" - 实现可伸缩、自动化的模型训练与进化。
>
> 📦 **模块代号:** `arf-cloud-training`
>
> ⚡ **所属:** ARF 云端平面 (Cloud Plane)

---

## 📋 1. 核心职责与设计理念

### 🎯 核心使命 (Core Mission)

作为ARF的“自动化模型进化平台”，训练模块的核心使命是**提供一个可伸缩的、自动化的、可复现的机器学习训练平台**。它使得开发者和自动化系统可以高效地利用`数据中心`的海量数据，进行分布式模型训练、微调和持续学习。其进化目标是超越简单的模型生产，成为一个能够**自动化处理Sim-to-Real迁移**并支持**大规模联邦学习**的智能进化引擎。

主要应用场景包括：

- **🏋️ 从零训练 (Training from Scratch):** 利用大规模的仿真和真实数据集，训练全新的模仿学习(IL)或强化学习(RL)模型。
- **🔄 增量微调 (Incremental Fine-tuning):** 利用`遥操作模块`采集到的“失败案例”或新的示教数据，对现有的VLA模型进行增量微调，实现模型的持续改进。
- **🌉 Sim-to-Real 自动化迁移:** 提供标准化的训练流水线，将在仿真环境中预训练好的模型，通过领域自适应等技术，自动迁移以适应真实世界。
- **🤖 联邦学习 (Federated Learning):** (未来) 协调分布在全球的机器人，在不上传隐私数据的前提下，进行模型参数的联合训练。
- **🔬 超参数优化 (Hyperparameter Optimization):** 自动进行大规模的超参数搜索实验，为特定模型找到最佳配置。
- **🎯 主动学习闭环:** 与`数据中心`联动，消费其智能采样的高价值数据子集，以更低的成本、更高的效率加速模型收敛。
- **🩺 硬件健康模型训练:** 利用`数据中心`汇集的硬件遥测数据，为`HAL`层训练用于预测性维护的故障预测和异常检测模型。

### 🏗️ 核心架构：“训练即服务” 与 “自动化进化” (Training-as-a-Service & Automated Evolution)

我们将复杂的模型训练过程，抽象为一个云原生的“服务”，开发者无需关心底层的GPU集群管理和分布式训练细节。

- **训练流水线 (Training Pipeline):** 每一次训练都被视为一个可编排的流水线（Pipeline）。这条流水线定义了从“数据准备->模型训练->模型验证->模型发布”的完整步骤。
- **任务队列与调度器 (Job Queue & Scheduler):** `训练模块`维护一个任务队列。开发者或自动化系统（如`评测模块`）向队列中提交一个“训练任务请求”。核心调度器负责从队列中取出任务，并向Kubernetes集群申请所需的GPU资源来执行。
- **实验跟踪 (Experiment Tracking):** 所有训练过程中的关键信息（代码版本、数据集版本、超参数、损失曲线、性能指标、产出模型）都将被自动记录和版本化，确保任何一次实验都是可追溯和可复现的。
- **联邦聚合器 (Federation Aggregator):** 作为一个新的核心组件，负责接收和安全聚合来自边缘节点的模型更新，是联邦学习的核心。



### ⚖️ 设计原则 (Design Principles)

- **🔄 可复现性 (Reproducibility):** 这是最高原则。任何一次训练，给定相同的代码、数据和配置，其结果必须是完全一致的。
- **🚀 可伸缩性 (Scalability):** 架构必须支持从单GPU节点的调试任务，到数百个GPU节点的大规模分布式训练任务的弹性伸缩。
- **🔌 框架无关 (Framework Agnostic):** 平台应能支持主流的AI框架（PyTorch, TensorFlow），而不是绑定某一个。
- **🤖 自动化 (Automation):** 尽可能地将训练流程自动化，实现“数据输入，模型输出”的理想状态。
- **🔒 隐私保护 (Privacy-Preserving):** 在涉及用户数据的学习场景中（如联邦学习），必须将保护用户隐私作为最高设计优先级。

---

## 📝 2. 核心需求 (Core Requirements)

| ID      | 需求描述               | 验收标准                                                     | 优先级         |
| :------ | :--------------------- | :----------------------------------------------------------- | :------------- |
| **TR1** | **分布式训练支持**     | 必须支持基于`PyTorch DDP` (DistributedDataParallel) 或 `Horovod` 的多机多卡分布式训练。 | **最高**       |
| **TR2** | **可配置的训练流水线** | 开发者必须能够通过一个YAML配置文件，定义训练所需的数据集、训练脚本、超参数和计算资源。 | **最高**       |
| **TR3** | **与数据中心集成**     | 训练流水线必须能够通过一个简单的查询语句，从`数据中心`高效地拉取和准备训练数据集。 | **最高**       |
| **TR4** | **实验跟踪与版本控制** | 必须自动记录每次训练运行的所有元数据，并将产出的模型与实验结果关联，存入`插件市场`。 | **高**         |
| **TR5** | **失败学习流程支持**   | 必须支持针对“失败案例”数据进行高效的增量微调(Fine-tuning)的特定流水线。 | **高**         |
| **TR6** | **资源隔离**           | 每个训练任务都必须运行在独立的、容器化的环境中，确保任务间的依赖和资源不互相干扰。 | **最高**       |
| **TR7** | **Sim-to-Real流水线**  | **[V1.1+ 新增]** 必须提供标准化的训练流水线，支持领域自适应等技术，以降低仿真模型在真实环境中的性能损失。 | **高 (V1.1+)** |
| **TR8** | **联邦学习支持**       | **[V1.1+ 新增]** 必须提供联邦学习聚合器，并为边缘端提供相应的训练代理，实现在不上传原始数据下的模型联合训练。 | **高 (V1.1+)** |

---

## ⚙️ 3. 关键功能与子模块架构

### 🧠 3.1 训练任务管理器 (Training Job Manager)

**工厂厂长角色**：这是一个用`Go`实现的、运行在Kubernetes上的核心服务，是“AI模型工厂”的大脑。

- **API端点:** 对外提供一个gRPC服务（`training.proto`），接收来自开发者（通过CLI）或自动化系统（如CI/CD）的训练任务请求。
- **任务解析与调度:** 解析用户提交的训练配置YAML，向`数据中心`请求数据，并动态生成Kubeflow或Ray的分布式训练任务YAML。
- **资源编排:** 调用Kubernetes API，在GPU集群上创建训练任务所需的Pods。
- **状态监控:** 持续监控训练任务的状态，并将日志和指标实时反馈给实验跟踪系统。

### 🏭 3.2 训练执行器 (Training Executor)

**生产车间角色**：每一个训练任务都是一个或多个运行在Kubernetes Pod中的**容器**。

- **数据加载器 (Data Loader):** 训练容器启动后的第一步，是根据任务配置中的数据查询语句，使用ARF SDK从`数据中心`下载并准备数据集。
- **训练脚本 (Training Script):** 容器的核心，即算法团队提供的Python训练代码。它会从指定的路径加载模型和数据，执行训练循环，并定期保存检查点(checkpoint)和输出日志。
- **指标报告器 (Metrics Reporter):** 在训练过程中，脚本通过一个轻量级的库，将损失值、准确率等指标实时上报给实验跟踪系统（如MLflow）。
- **模型发布器 (Model Publisher):** 训练成功结束后，将最终的模型文件、权重、以及相关的元数据，打包并发布到`插件市场`。

### V1.1 新增高级功能子模块

### 🌉 3.3 Sim-to-Real 流水线编排器 (Sim-to-Real Pipeline Orchestrator)

**摆渡人角色**：这是`训练任务管理器`内部的一个新逻辑单元。

- **职责:** 负责解析和执行包含Sim-to-Real阶段的训练任务。它会编排一个多阶段的流水线：第一阶段在大量仿真数据上进行预训练；第二阶段则使用不同的算法（如Domain Adversarial Training）和少量真实数据，对模型进行微调和对齐。

### 🤖 3.4 联邦学习聚合器 (Federated Learning Aggregator)

**中央协调员角色**：这是一个新的、长期运行的服务，或者是由`训练任务管理器`按轮次（Round）启动的周期性任务。

- **职责:**
  1. 向`舰队管理`模块请求一组可参与本轮训练的边缘设备。
  2. 向这些设备分发全局模型和训练指令。
  3. 等待并接收来自边缘设备的加密模型更新。
  4. 使用安全聚合算法（如FedAvg）将所有更新融合成一个新的全局模型。
  5. 重复此过程，直到模型收敛。

### 💡 3.5 微经验泛化流水线 (Micro-Experience Generalization Pipeline)

**知识萃取师角色**：除了大规模训练，`训练模块`还提供轻量级的、专门设计的流水线，用于将`数据中心`中单个或少量的“宝贵经验”数据（如一次成功的专家示教）快速泛化为一个可部署的局部模型或策略更新，以支持`舰队管理`的群体知识共享工作流。

---

## 🔗 4. 接口设计与数据流

`训练模块`是连接“数据”与“模型”的核心枢纽。

### 📥 输入数据流

| **数据源**         | **数据类型**                     | **优先级** | **延迟要求** | **示例场景**                   |
| :----------------- | :------------------------------- | :--------- | :----------- | :----------------------------- |
| **开发者(CLI)**    | `StartTrainingJobRequest` (gRPC) | `NORMAL`   | `< 5s`       | 开发者手动提交一个训练任务     |
| **遥操作模块/DMS** | `ExpertTrajectoryData`           | `NORMAL`   | N/A (离线)   | 新的示教数据被上传到数据中心   |
| **数据中心**       | 结构化的训练数据集               | `HIGH`     | 高带宽       | 训练容器拉取PB级数据           |
| **插件市场**       | 基础模型 (Base Model)            | `NORMAL`   | N/A          | 进行微调任务时，下载预训练模型 |

### 📤 输出数据流

| **目标模块**     | **数据类型**       | **保证**         | **性能指标**           |
| :--------------- | :----------------- | :--------------- | :--------------------- |
| **插件市场**     | 训练好的模型插件   | 可靠上传、版本化 | -                      |
| **评测模块**     | `EvaluationTask`   | 自动触发         | 训练完成后自动开始评测 |
| **实验跟踪系统** | 训练日志、性能指标 | 实时上报         | -                      |

### 🧬 核心API草案 (`training.proto`)

```protobuf
// protos/arf/cloud/v1/training.proto
syntax = "proto3";

package arf.cloud.v1;

import "arf/v1/common.proto";

// 训练任务状态
enum JobStatus {
  // ... PENDING, RUNNING, SUCCEEDED, FAILED ...
}

// 训练服务定义
service TrainingService {
  // 提交一个新的训练任务
  rpc StartTrainingJob(StartTrainingJobRequest) returns (StartTrainingJobResponse);
  // 获取一个训练任务的状态
  rpc GetTrainingJobStatus(GetTrainingJobStatusRequest) returns (JobStatus);
  // [V1.1 新增] 联邦学习客户端调用的接口
  // 客户端（边缘机器人）上报模型更新
  rpc SubmitModelUpdate(SubmitModelUpdateRequest) returns (SubmitModelUpdateResponse);
  // 客户端获取最新的全局模型
  rpc GetGlobalModel(GetGlobalModelRequest) returns (GetGlobalModelResponse);
  // ... 其他管理任务的方法 ...
}

message StartTrainingJobRequest {
    string display_name = 1; // 本次训练任务的名称
    arf.v1.PluginIdentifier training_script_plugin = 2; // 包含训练代码的插件ID
    string dataset_query = 3; // 用于从Data Hub查询数据的SQL或DSL,主要是仿真数据
    map<string, string> hyperparameters = 4; // 超参数
    optional arf.v1.PluginIdentifier base_model_plugin = 5; // (可选) 用于微调的基础模型
    
    // [V1.1 更新] 增加主动学习的数据源策略
    oneof data_source {
        string dataset_query = 3; // 传统方式：被动查询
        ActiveLearningStrategy active_learning = 8; // V1.1+ 新增：主动学习
    }

    // [V1.1 新增] 训练模式
    oneof training_mode {
        SimToRealStrategy sim_to_real_strategy = 6;
        FederatedLearningConfig federated_learning_config = 7;
    }
}
message StartTrainingJobResponse {
    string job_id = 1;
}

// Sim-to-Real 策略配置
message SimToRealStrategy {
    string adaptation_algorithm = 1; // e.g., "DANN"
    string real_data_query = 2;      // 用于查询少量真实数据的SQL
}

// ... 其他请求和响应消息定义 ...
```

------



## 🛠️ 5. 技术栈与开发环境





### 💻 核心技术栈



| **技术领域**     | **选型**                         | **版本要求** | **用途说明**               |
| ---------------- | -------------------------------- | ------------ | -------------------------- |
| **核心服务语言** | **Go**                           | `1.21+`      | 构建高并发的训练任务管理器 |
| **训练脚本语言** | **Python**                       | `3.10+`      | 主流AI框架的开发语言       |
| **MLOps编排**    | **Kubeflow / Ray on Kubernetes** | 最新稳定版   | 管理和调度分布式训练任务   |
| **实验跟踪**     | **MLflow / Weights & Biases**    | 最新稳定版   | 记录和比较实验结果         |
| **AI框架**       | **PyTorch, Horovod**             | `2.0+`       | 实现分布式训练             |

------



## 🔧 6. 开发实施细节





### 🏗️ 6.1 项目结构 V1



```
services/cloud-plane/training-manager/  # 训练任务管理器 (Go)
├── internal/
│   ├── scheduler/                    # Kubeflow/Ray任务调度逻辑
│   └── server/                       # gRPC服务器实现
├── Dockerfile
└── ...

templates/
└── training-pod/                     # 训练执行器的Pod模板
    ├── Dockerfile                    # 包含PyTorch, Horovod和ARF SDK
    ├── run_training.py               # 容器入口脚本，负责数据下载、启动训练
    └── ...
```



### 🧪 6.2 测试与验证策略



- **单元测试:** 对`训练任务管理器`的调度逻辑进行单元测试。
- **集成测试:**
  - **数据拉取测试:** 验证训练容器能够根据查询语句，成功从`数据中心`拉取到正确的数据。
  - **分布式训练测试:** 在一个最小化的2节点集群上，运行一个简单的分布式训练任务（如训练一个MNIST模型），验证多节点间的通信和同步是否正常。
  - **端到端流水线测试:** 提交一个完整的训练任务，验证其能否成功执行，并将最终的模型和日志正确地发布到`插件市场`和实验跟踪系统。

------



## 🚀 7. 开发任务 (Getting Started)





#### **第一阶段：单机训练流水线 (Single-Node Pipeline)**



- **任务1：开发`训练任务管理器`原型**
  - **交付物:** 一个Go服务，能接收`StartTrainingJob` gRPC请求，并在Kubernetes上创建一个单节点的Pod来执行训练。
- **任务2：开发基础训练容器**
  - **交付物:** 一个标准的Docker镜像，包含PyTorch和ARF SDK，能够接收环境变量传入的超参数和数据路径。
- **任务3：实现与`数据中心`的集成**
  - **交付物:** 训练容器的入口脚本能够使用SDK，根据传入的`dataset_query`，从`数据中心`下载数据。
- **任务4：实现与`插件市场`的集成**
  - **交付物:** 训练脚本在训练结束后，能将产出的模型文件打包，并上传到`插件市场`。



#### **第二阶段：分布式训练与实验跟踪 (Distributed Training & Tracking)**



- **任务1：集成Kubeflow或Ray**
  - **交付物:** `训练任务管理器`能够生成并应用`PyTorchJob` (Kubeflow) 或 `RayJob` 的CRD，以启动一个多节点的分布式训练任务。
- **任务2：集成MLflow**
  - **交付物:** 训练脚本能够自动将超参数、训练过程中的metrics（loss, accuracy）和最终的模型，记录到MLflow服务器。
- **任务3：提供`arf-cli`支持**
  - **交付物:** 开发者可以通过`arf-cli training start/status/logs`等命令，来管理和监控训练任务。



#### **第三阶段：自动化与失败学习 (Automation & Failure Learning)**



- **任务1：实现“失败案例”微调流水线**
  - **交付物:** 创建一个专门的训练流水线模板，该模板被优化用于加载少量“失败案例”数据，并对一个现有的大模型进行高效微调。
- **任务2：与`评测模块`联动**
  - **交付物:** 实现训练任务成功结束后，自动触发`评测模块`对新生成的模型进行标准化评测的流程。
- **任务3：实现超参数优化支持**
  - **交付物:** 集成Optuna或Ray Tune，允许开发者提交一个带有搜索空间的训练任务，由平台自动进行超参数寻优。



#### **第四阶段：联邦学习与高级功能 (Federated Learning & Advanced Features)**



- **任务1：设计联邦学习架构**
  - **交付物:** 详细设计`DMS`边缘端代理与云端`训练模块`聚合器之间的安全通信和模型聚合协议。
- **任务2：实现联邦学习聚合器**
  - **交付物:** `训练模块`中增加一个联邦学习聚合器，能够接收来自多个边缘节点的模型更新，并进行安全聚合。
- **任务3：压力与成本优化**
  - **交付物:** 对大规模训练任务进行性能和成本分析，并引入对GPU Spot实例的支持以降低训练成本。

#### **第五阶段及以后：迈向自动化模型进化 (Towards Automated Model Evolution)**



*此部分为V1.1及后续版本规划，旨在构建更高阶的智能闭环。*

- **任务5.1: 实现Sim-to-Real训练流水线原型**
  - **交付物:** 创建一个支持Sim-to-Real的训练流水线模板。在一个标准测试任务中（如仿真环境抓取->真实环境抓取），验证使用该流水线训练出的模型，其在真实环境中的成功率显著高于仅用仿真数据训练的模型。
- **任务5.2: 开发联邦学习聚合器**
  - **交付物:** 实现`联邦学习聚合器`服务。`训练服务`新增`SubmitModelUpdate`和`GetGlobalModel`两个RPC接口。
- **任务5.3: 开发联邦学习边缘端代理**
  - **交付物:** 提供一个轻量级的Python库或ACR容器，能够在边缘机器人上安全地执行本地训练，并与云端聚合器通信。
- **任务5.4: 端到端联邦学习测试**
  - **交付物:** 在一个模拟环境中（例如，启动10个代表边缘机器人的Docker容器），完整地运行一个联邦学习任务，并验证全局模型的性能确实随着联邦轮次的增加而提升。
- **任务5.5: 实现主动学习与群体智能工作流**
  - **交付物:**
    - 与`Data Hub`团队协作，实现一个端到端的主动学习流程。
    - 与`Fleet Management`团队协作，实现一个完整的“微经验泛化”工作流，支持群体知识共享。



