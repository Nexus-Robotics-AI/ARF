# 🔥 ARF 模块开发参考文档：训练模块 (Training)

> 🎯 **角色定位:** ARF的"AI模型工厂" - 实现可伸缩、自动化的模型训练与进化。
>
> 📦 **模块代号:** `arf-cloud-training`
>
> ⚡ **所属:** ARF 云端平面 (Cloud Plane)

---

## 📋 1. 核心职责与设计理念

### 🎯 核心使命 (Core Mission)

作为ARF的“AI模型工厂”，训练模块的核心使命是**提供一个可伸缩的、自动化的、可复现的机器学习训练平台**。它使得开发者和自动化系统可以高效地利用`数据中心`的海量数据，进行分布式模型训练、微调和持续学习，为整个生态系统源源不断地输送更强大的智能。

主要应用场景包括：

- **🏋️ 从零训练 (Training from Scratch):** 利用大规模的仿真和真实数据集，训练全新的模仿学习(IL)或强化学习(RL)模型。
- **🔄 增量微调 (Incremental Fine-tuning):** 利用`遥操作模块`采集到的“失败案例”或新的示教数据，对现有的VLA模型进行增量微调，实现模型的持续改进。
- **🤖 联邦学习 (Federated Learning):** (未来) 协调分布在全球的机器人，在不上传隐私数据的前提下，进行模型参数的联合训练。
- **🔬 超参数优化 (Hyperparameter Optimization):** 自动进行大规模的超参数搜索实验，为特定模型找到最佳配置。

### 🏗️ 核心架构：“训练即服务” (Training-as-a-Service)

我们将复杂的模型训练过程，抽象为一个云原生的“服务”，开发者无需关心底层的GPU集群管理和分布式训练细节。

- **训练流水线 (Training Pipeline):** 每一次训练都被视为一个可编排的流水线（Pipeline）。这条流水线定义了从“数据准备->模型训练->模型验证->模型发布”的完整步骤。
- **任务队列与调度器 (Job Queue & Scheduler):** `训练模块`维护一个任务队列。开发者或自动化系统（如`评测模块`）向队列中提交一个“训练任务请求”。核心调度器负责从队列中取出任务，并向Kubernetes集群申请所需的GPU资源来执行。
- **实验跟踪 (Experiment Tracking):** 所有训练过程中的关键信息（代码版本、数据集版本、超参数、损失曲线、性能指标、产出模型）都将被自动记录和版本化，确保任何一次实验都是可追溯和可复现的。

### ⚖️ 设计原则 (Design Principles)

- **🔄 可复现性 (Reproducibility):** 这是最高原则。任何一次训练，给定相同的代码、数据和配置，其结果必须是完全一致的。
- **🚀 可伸缩性 (Scalability):** 架构必须支持从单GPU节点的调试任务，到数百个GPU节点的大规模分布式训练任务的弹性伸缩。
- **🔌 框架无关 (Framework Agnostic):** 平台应能支持主流的AI框架（PyTorch, TensorFlow），而不是绑定某一个。
- **🤖 自动化 (Automation):** 尽可能地将训练流程自动化，实现“数据输入，模型输出”的理想状态。

---

## 📝 2. 核心需求 (Core Requirements)

| ID      | 需求描述               | 验收标准                                                     | 优先级   |
| :------ | :--------------------- | :----------------------------------------------------------- | :------- |
| **TR1** | **分布式训练支持**     | 必须支持基于`PyTorch DDP` (DistributedDataParallel) 或 `Horovod` 的多机多卡分布式训练。 | **最高** |
| **TR2** | **可配置的训练流水线** | 开发者必须能够通过一个YAML配置文件，定义训练所需的数据集、训练脚本、超参数和计算资源。 | **最高** |
| **TR3** | **与数据中心集成**     | 训练流水线必须能够通过一个简单的查询语句，从`数据中心`高效地拉取和准备训练数据集。 | **最高** |
| **TR4** | **实验跟踪与版本控制** | 必须自动记录每次训练运行的所有元数据，并将产出的模型与实验结果关联，存入`插件市场`。 | **高**   |
| **TR5** | **失败学习流程支持**   | 必须支持针对“失败案例”数据进行高效的增量微调(Fine-tuning)的特定流水线。 | **高**   |
| **TR6** | **资源隔离**           | 每个训练任务都必须运行在独立的、容器化的环境中，确保任务间的依赖和资源不互相干扰。 | **最高** |

---

## ⚙️ 3. 关键功能与子模块架构

### 🧠 3.1 训练任务管理器 (Training Job Manager)

**工厂厂长角色**：这是一个用`Go`实现的、运行在Kubernetes上的核心服务，是“AI模型工厂”的大脑。

- **API端点:** 对外提供一个gRPC服务（`training.proto`），接收来自开发者（通过CLI）或自动化系统（如CI/CD）的训练任务请求。
- **任务解析与调度:** 解析用户提交的训练配置YAML，向`数据中心`请求数据，并动态生成Kubeflow或Ray的分布式训练任务YAML。
- **资源编排:** 调用Kubernetes API，在GPU集群上创建训练任务所需的Pods。
- **状态监控:** 持续监控训练任务的状态，并将日志和指标实时反馈给实验跟踪系统。

### 🏭 3.2 训练执行器 (Training Executor)

**生产车间角色**：每一个训练任务都是一个或多个运行在Kubernetes Pod中的**容器**。

- **数据加载器 (Data Loader):** 训练容器启动后的第一步，是根据任务配置中的数据查询语句，使用ARF SDK从`数据中心`下载并准备数据集。
- **训练脚本 (Training Script):** 容器的核心，即算法团队提供的Python训练代码。它会从指定的路径加载模型和数据，执行训练循环，并定期保存检查点(checkpoint)和输出日志。
- **指标报告器 (Metrics Reporter):** 在训练过程中，脚本通过一个轻量级的库，将损失值、准确率等指标实时上报给实验跟踪系统（如MLflow）。
- **模型发布器 (Model Publisher):** 训练成功结束后，将最终的模型文件、权重、以及相关的元数据，打包并发布到`插件市场`。

---

## 🔗 4. 接口设计与数据流

`训练模块`是连接“数据”与“模型”的核心枢纽。

### 📥 输入数据流

| **数据源**         | **数据类型**                     | **优先级** | **延迟要求** | **示例场景**                   |
| :----------------- | :------------------------------- | :--------- | :----------- | :----------------------------- |
| **开发者(CLI)**    | `StartTrainingJobRequest` (gRPC) | `NORMAL`   | `< 5s`       | 开发者手动提交一个训练任务     |
| **遥操作模块/DMS** | `ExpertTrajectoryData`           | `NORMAL`   | N/A (离线)   | 新的示教数据被上传到数据中心   |
| **数据中心**       | 结构化的训练数据集               | `HIGH`     | 高带宽       | 训练容器拉取PB级数据           |
| **插件市场**       | 基础模型 (Base Model)            | `NORMAL`   | N/A          | 进行微调任务时，下载预训练模型 |

### 📤 输出数据流

| **目标模块**     | **数据类型**       | **保证**         | **性能指标**           |
| :--------------- | :----------------- | :--------------- | :--------------------- |
| **插件市场**     | 训练好的模型插件   | 可靠上传、版本化 | -                      |
| **评测模块**     | `EvaluationTask`   | 自动触发         | 训练完成后自动开始评测 |
| **实验跟踪系统** | 训练日志、性能指标 | 实时上报         | -                      |

### 🧬 核心API草案 (`training.proto`)

```protobuf
// protos/arf/cloud/v1/training.proto
syntax = "proto3";

package arf.cloud.v1;

import "arf/v1/common.proto";

// 训练任务状态
enum JobStatus {
  // ... PENDING, RUNNING, SUCCEEDED, FAILED ...
}

// 训练服务定义
service TrainingService {
  // 提交一个新的训练任务
  rpc StartTrainingJob(StartTrainingJobRequest) returns (StartTrainingJobResponse);
  // 获取一个训练任务的状态
  rpc GetTrainingJobStatus(GetTrainingJobStatusRequest) returns (JobStatus);
  // ... 其他管理任务的方法 ...
}

message StartTrainingJobRequest {
    string display_name = 1; // 本次训练任务的名称
    arf.v1.PluginIdentifier training_script_plugin = 2; // 包含训练代码的插件ID
    string dataset_query = 3; // 用于从Data Hub查询数据的SQL或DSL
    map<string, string> hyperparameters = 4; // 超参数
    optional arf.v1.PluginIdentifier base_model_plugin = 5; // (可选) 用于微调的基础模型
}
message StartTrainingJobResponse {
    string job_id = 1;
}

// ... 其他请求和响应消息定义 ...
```

------



## 🛠️ 5. 技术栈与开发环境





### 💻 核心技术栈



| **技术领域**     | **选型**                         | **版本要求** | **用途说明**               |
| ---------------- | -------------------------------- | ------------ | -------------------------- |
| **核心服务语言** | **Go**                           | `1.21+`      | 构建高并发的训练任务管理器 |
| **训练脚本语言** | **Python**                       | `3.10+`      | 主流AI框架的开发语言       |
| **MLOps编排**    | **Kubeflow / Ray on Kubernetes** | 最新稳定版   | 管理和调度分布式训练任务   |
| **实验跟踪**     | **MLflow / Weights & Biases**    | 最新稳定版   | 记录和比较实验结果         |
| **AI框架**       | **PyTorch, Horovod**             | `2.0+`       | 实现分布式训练             |

------



## 🔧 6. 开发实施细节





### 🏗️ 6.1 项目结构 V1



```
services/cloud-plane/training-manager/  # 训练任务管理器 (Go)
├── internal/
│   ├── scheduler/                    # Kubeflow/Ray任务调度逻辑
│   └── server/                       # gRPC服务器实现
├── Dockerfile
└── ...

templates/
└── training-pod/                     # 训练执行器的Pod模板
    ├── Dockerfile                    # 包含PyTorch, Horovod和ARF SDK
    ├── run_training.py               # 容器入口脚本，负责数据下载、启动训练
    └── ...
```



### 🧪 6.2 测试与验证策略



- **单元测试:** 对`训练任务管理器`的调度逻辑进行单元测试。
- **集成测试:**
  - **数据拉取测试:** 验证训练容器能够根据查询语句，成功从`数据中心`拉取到正确的数据。
  - **分布式训练测试:** 在一个最小化的2节点集群上，运行一个简单的分布式训练任务（如训练一个MNIST模型），验证多节点间的通信和同步是否正常。
  - **端到端流水线测试:** 提交一个完整的训练任务，验证其能否成功执行，并将最终的模型和日志正确地发布到`插件市场`和实验跟踪系统。

------



## 🚀 7. 开发任务 (Getting Started)





#### **第一阶段：单机训练流水线 (Single-Node Pipeline)**



- **任务1：开发`训练任务管理器`原型**
  - **交付物:** 一个Go服务，能接收`StartTrainingJob` gRPC请求，并在Kubernetes上创建一个单节点的Pod来执行训练。
- **任务2：开发基础训练容器**
  - **交付物:** 一个标准的Docker镜像，包含PyTorch和ARF SDK，能够接收环境变量传入的超参数和数据路径。
- **任务3：实现与`数据中心`的集成**
  - **交付物:** 训练容器的入口脚本能够使用SDK，根据传入的`dataset_query`，从`数据中心`下载数据。
- **任务4：实现与`插件市场`的集成**
  - **交付物:** 训练脚本在训练结束后，能将产出的模型文件打包，并上传到`插件市场`。



#### **第二阶段：分布式训练与实验跟踪 (Distributed Training & Tracking)**



- **任务1：集成Kubeflow或Ray**
  - **交付物:** `训练任务管理器`能够生成并应用`PyTorchJob` (Kubeflow) 或 `RayJob` 的CRD，以启动一个多节点的分布式训练任务。
- **任务2：集成MLflow**
  - **交付物:** 训练脚本能够自动将超参数、训练过程中的metrics（loss, accuracy）和最终的模型，记录到MLflow服务器。
- **任务3：提供`arf-cli`支持**
  - **交付物:** 开发者可以通过`arf-cli training start/status/logs`等命令，来管理和监控训练任务。



#### **第三阶段：自动化与失败学习 (Automation & Failure Learning)**



- **任务1：实现“失败案例”微调流水线**
  - **交付物:** 创建一个专门的训练流水线模板，该模板被优化用于加载少量“失败案例”数据，并对一个现有的大模型进行高效微调。
- **任务2：与`评测模块`联动**
  - **交付物:** 实现训练任务成功结束后，自动触发`评测模块`对新生成的模型进行标准化评测的流程。
- **任务3：实现超参数优化支持**
  - **交付物:** 集成Optuna或Ray Tune，允许开发者提交一个带有搜索空间的训练任务，由平台自动进行超参数寻优。



#### **第四阶段：联邦学习与高级功能 (Federated Learning & Advanced Features)**



- **任务1：设计联邦学习架构**
  - **交付物:** 详细设计`DMS`边缘端代理与云端`训练模块`聚合器之间的安全通信和模型聚合协议。
- **任务2：实现联邦学习聚合器**
  - **交付物:** `训练模块`中增加一个联邦学习聚合器，能够接收来自多个边缘节点的模型更新，并进行安全聚合。
- **任务3：压力与成本优化**
  - **交付物:** 对大规模训练任务进行性能和成本分析，并引入对GPU Spot实例的支持以降低训练成本。

