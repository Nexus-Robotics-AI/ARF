# 🔥 ARF 模块开发参考文档：决策智能层 (DIL)  V1.1

> 🎯 **角色定位:** ARF的"大脑" - 编排感知与行动，实现复杂任务逻辑。
>
> 📦 **模块代号:** `arf-edge-dil`
>
> ⚡ **所属:** ARF 边缘平台 (Edge Plane)

## 📋 1. 核心职责与设计理念

### 🎯 核心使命 (Core Mission)

作为ARF的“大脑”，DIL的核心使命是**编排和调用**`ACR`提供的各种原子化“算法能力”，融合来自`DMS`的多模态信息，并根据当前的任务目标，**生成一系列有意义的行动指令**，最终通过`HAL`层作用于物理世界。

它的进化目标是超越简单的任务编排，成为一个能够**在线学习、主动预测并进行长期记忆交互**的认知代理。

主要应用场景包括：

- **🤖 任务规划与执行:** 将用户的抽象指令（如“给我拿个苹果”）分解为一系列具体的机器人动作。
- **🧠 行为决策:** 根据环境变化和自身状态，动态地选择最合适的行为策略（如避障、探索、交互）。
- **🧩 知识推理:** 结合大型语言模型(LLM)和本地知识库，进行常识推理，以更好地理解和完成任务。
- **🛡️ 安全监控:** 作为系统安全的最后一道防线，持续监控系统状态，并在检测到危险时触发安全策略。
- **🌱 在线持续学习:** 在任务执行过程中，利用新的交互数据在边缘端进行轻量级模型微调，实现对环境的快速适应

### 🏗️ 核心架构：分层决策与策略模式 + 预测性世界模型 (Hierarchical Decision + Predictive World Model)

DIL的架构设计将“长期规划”与“短期反应”分离，并允许动态加载不同的“行为策略”。

- **分层决策 (Hierarchical):**
  - **高层规划器 (High-level Planner):** 负责将任务目标分解为一系列逻辑子任务（e.g., `MapsTo(kitchen)`, `Detect(apple)`, `Grasp(apple)`）。它可以是符号化的规划器或基于LLM的代理。
  - **低层控制器 (Low-level Controller):** 负责执行具体的子任务，将逻辑指令转化为连续的控制信号。它可以是基于强化学习(RL)的策略、行为树(BT)或经典控制器。
- **预测性世界模型 (Predictive World Model):** 内部的“世界模型” 不再仅仅记录当前状态，而是升级为一个主动的“未来状态预测器”。它能预测环境中其他动态实体（如人）的短期意图和行为，为前瞻性决策提供依据。
- **策略模式 (Strategy Pattern):** 不同的机器人行为（如导航、抓取）被封装为可插拔的“策略”模块。DIL可以根据任务上下文，动态地加载和切换这些策略。

### ⚖️ 设计原则 (Design Principles)

- **🧠 灵活性:** 架构必须足够灵活，以支持从传统的行为树到前沿的端到端VLA模型的各种决策范式。
- **🔌 可扩展性:** 添加一个新的机器人技能或决策逻辑，应该是可插拔的，不应需要修改核心代码。
- **🧩 模块化:** 任务规划、行为决策、安全监控等功能应在代码层面解耦。
- **🤔 可解释性:** 决策过程应尽可能地可追溯和可调试，方便开发者理解机器人的“想法”。
- **🌱 持续进化 (Continual Evolution):** 必须提供接口和机制，支持模型和策略的在线学习与自适应，让智能在边缘端也能持续进化。

## 📝 2. 核心需求 (Core Requirements)

| **ID** | **需求描述**                            | **验收标准**                                                 | **优先级**     |
| ------ | --------------------------------------- | ------------------------------------------------------------ | -------------- |
| **L1** | **多模态信息融合 (Multi-modal Fusion)** | DIL必须能够订阅并融合来自`DMS`的多种数据源（如视觉特征、目标列表、IMU、文本指令）作为决策依据。 | **最高**       |
| **L2** | **任务逻辑编排 (Task Orchestration)**   | 必须提供一种机制（如行为树、状态机），用于编排对`ACR`和`HAL`模块的调用，以完成复杂的多步任务。 | **最高**       |
| **L3** | **策略库与动态加载 (Policy Library)**   | DIL应支持一个“策略库”，可以从中根据任务需求动态加载和执行不同的行为策略（如导航策略、抓取策略）。 | **高**         |
| **L4** | **知识推理能力 (Knowledge Reasoning)**  | 必须提供接口，允许DIL调用外部LLM服务和内部知识库，以进行任务规划和常识推理。 | **高**         |
| **L5** | **安全监控 (Safety Monitoring)**        | 必须持续监控来自`HAL`的硬件状态和来自`ACR`的感知信息（如置信度图），并在检测到潜在风险时，能够覆盖或中止当前任务，执行安全策略。 | **最高**       |
| **L6** | **状态管理 (State Management)**         | 必须维护一个内部的“世界模型 (World Model)”或“信念状态 (Belief State)”，持续追踪机器人自身和环境的关键状态。 | **高**         |
| **L7** | **在线学习与自适应**                    | 必须提供机制，支持在边缘端利用新数据对本地模型进行轻量级微调。 | **高 (V1.1+)** |
| **L8** | **预测性世界建模**                      | “世界模型”必须具备短期未来预测能力，能预测环境中动态实体的行为。 | **中 (V1.1+)** |
| **L9** | **长期记忆接口**                        | 必须提供API，用于查询和更新与特定用户或实体关联的长期记忆。  | **中 (V1.1+)** |

## ⚙️ 3. 关键功能与子模块架构

### 🧠 3.1 任务规划器 (Task Planner)

**指挥官角色**：负责高层逻辑规划，将抽象目标转化为具体的行动步骤。

- **LLM代理 (LLM Agent):**
  - **工作流程:** 将用户指令和当前场景描述打包成一个Prompt，发送给LLM服务。LLM返回的是一个结构化的子任务序列（e.g., a JSON list of steps）。
  - **本地知识库 (Local KB):** 用于缓存和检索与特定环境和任务相关的知识，减少对LLM的依赖，并提高推理速度。

### 🧩 3.2 行为树/状态机管理器 (BT/FSM Manager)

**战术执行官角色**：负责执行任务规划器生成的每一个子任务。

- **行为树 (Behavior Tree):** 是实现复杂、异步、响应式行为的理想工具。我们将提供一个行为树引擎，以及一系列可被复用的“行为节点”。
  - **条件节点:** `IsObjectDetected?`, `IsBatteryLow?`
  - **动作节点:** `CallACRService(detect_object)`, `CallHALService(move_arm)`
- **策略库 (Policy Library):** 每一个复杂的“动作节点”（如`MapsTo`) 内部，都会调用一个具体的“策略”来实现。例如，`MapsTo`节点会去策略库中查找当前最优的导航策略来执行。

### 🛡️ 3.3 安全调度器 (Safety Scheduler)

**安全督察角色**：这是位于决策指令输出到`HAL`之前的最后一道关卡。

- **工作流程:** 它会接收来自行为树的“期望指令”，同时接收来自各处的“安全状态信息”（如IMU倾角、电机温度、视觉避障模块的风险评估）。
- **决策逻辑:**
  - 如果安全状态正常，则将“期望指令”直接透传给`HAL`。
  - 如果检测到风险（如机器人即将碰撞），它会**覆盖**“期望指令”，并向`HAL`发送一个“安全指令”（如紧急停止）。

### 🌱 3.4 在线学习管理器 (Online Learning Manager)



**经验总结师角色**：负责DIL在边缘端的持续进化。

- **工作流程:** 监控任务执行过程，特别是`遥操作模块`介入的“失败学习”场景。当收集到足够的新样本（如新的抓取姿态、新的避障轨迹）时，它会触发一个低优先级的后台任务，对本地的某个`ACR`模型（如抓取策略网络）进行几个迭代的微调。



### 🔮 3.5 预测性世界模型 (Predictive World Model)



**预言家角色**：从被动记录当前状态，升级为主动预测未来。

- **工作流程:** 订阅环境中动态实体（如人类）的轨迹和状态信息。内部运行一个由云端`训练模块`训练好的“时空预测模型”，持续预测这些实体在接下来几秒内的可能位置和行为，并将这些预测结果作为决策的额外输入信息。



### 📚 3.6 长期记忆接口 (Long-term Memory Interface)



**记忆管家角色**：负责机器人的个性化记忆。

- **工作流程:** 提供一个客户端，用于与云端`数据中心`的“记忆图谱”数据库进行通信。在进行自然语言交互或执行个性化任务时，DIL会通过此接口查询用户的偏好和历史信息（如“用户最喜欢的杯子是蓝色的”），并将新的重要信息（如“今天用户把钥匙放在了玄关的桌子上”）写入记忆库。

### 🧩**3.7模式管理器 (Mode Manager):**

- 这是`DIL`内部一个全新的核心组件，负责管理机器人的全局状态（`AUTONOMOUS` vs `TELEOPERATION`）。
- 它需要提供一个内部API，供其他逻辑（如失败检测器）调用以请求模式切换。

### 🧩3.8**失败检测器 (Failure Detector):**

- 这是一个新的逻辑节点或子系统。
- **职责:** 监控自主任务的执行状态（如通过目标检测验证抓取是否成功），并在检测到失败时，调用“模式管理器”切换到遥操作模式。

### 🧩3.9**修改决策流以支持残差学习:**

- `DIL`的最终动作输出逻辑需要被修改。
- **原流程:** `VLA -> HAL`
- **新流程:** `VLA -> a_vla` -> (等待`ACR残差网络`发布`Δa`) -> `a_final = a_vla + Δa` -> `HAL`。这需要在DIL内部实现一个简单的同步或融合节点。



## 🔗 4. 接口设计与数据流

DIL作为一个核心的Python服务，是系统中信息流的“汇聚点”和“发源点”。

### 📥 输入数据流

| **数据源**       | **数据类型**                    | **优先级** | **延迟要求** | **示例场景**             |
| ---------------- | ------------------------------- | ---------- | ------------ | ------------------------ |
| **DMS数据总线**  | `BusMessage` (包含所有感知结果) | `HIGH`     | `< 20ms`     | 接收ACR的目标检测结果    |
| **API应用层**    | `TaskRequest` (gRPC)            | `NORMAL`   | `< 100ms`    | 接收用户的语音或文本指令 |
| **知识层 (LLM)** | `KnowledgeFragment` (gRPC)      | `NORMAL`   | `< 2s`       | 获取LLM对任务的分解      |

### 📤 输出数据流

| **目标模块**    | **数据类型**                             | **保证**     | **性能指标**                |
| --------------- | ---------------------------------------- | ------------ | --------------------------- |
| **HAL执行器**   | `MotorCommand` (gRPC)                    | 低延迟、可靠 | 指令下发延迟 < 10ms         |
| **ACR算法层**   | `StartContainerRequest` (gRPC)           | 异步响应     | 动态加载算法服务            |
| **DMS数据总线** | `DILStatus`, `TaskProgress` (BusMessage) | 状态广播     | DIL内部状态和任务进度的上报 |
| **API应用层**   | `TaskResponse` (gRPC)                    | 异步响应     | 向用户反馈任务结果          |

### 🧬 核心API草案 (`dil.proto`)

```protobuf
// protos/arf/edge/v1/dil.proto
syntax = "proto3";

package arf.edge.v1;

// 任务状态
message TaskStatus {
    string task_id = 1;
    string status = 2; // e.g., "PENDING", "RUNNING", "SUCCEEDED", "FAILED"
    string message = 3;
}

// DIL对外提供的任务管理服务
service DILService {
  // 提交一个高层任务（如文本指令）
  rpc SubmitTask(SubmitTaskRequest) returns (SubmitTaskResponse);
  // 获取一个任务的当前状态
  rpc GetTaskStatus(GetTaskStatusRequest) returns (TaskStatus);
  // 取消一个正在运行的任务
  rpc CancelTask(CancelTaskRequest) returns (CancelTaskResponse);
  // [V1.1 新增] 手动设置机器人操作模式
  rpc SetOperationMode(SetOperationModeRequest) returns (SetOperationModeResponse);
}

message SubmitTaskRequest {
    string task_description = 1; // e.g., "bring me the red apple from the table"
}
message SubmitTaskResponse {
    string task_id = 1;
}
message GetTaskStatusRequest {
    string task_id = 1;
}
message CancelTaskRequest {
    string task_id = 1;
}
message CancelTaskResponse {
    bool success = 1;
}

enum OperationMode {
    AUTONOMOUS = 0;
    TELEOPERATION = 1;
}

message SetOperationModeRequest {
    OperationMode mode = 1;
}
message SetOperationModeResponse {
    bool success = 1;
}
```

## 🛠️ 5. 技术栈与开发环境

### 💻 核心技术栈

| **技术领域** | **选型**     | **版本要求** | **用途说明**             |
| ------------ | ------------ | ------------ | ------------------------ |
| **编程语言** | **Python**   | `3.10+`      | AI生态的核心，快速迭代   |
| **AI框架**   | **PyTorch**  | `2.0+`       | 运行端到端的神经网络策略 |
| **行为树**   | **py_trees** | `2.1+`       | 实现结构化的任务逻辑     |
| **gRPC框架** | **grpcio**   | 最新稳定版   | 与其他模块的服务接口     |
| **测试框架** | **Pytest**   | 最新稳定版   | 单元测试和集成测试       |

## 🔧 6. 开发实施细节

### 🏗️ 6.1 项目结构 V1

```
services/edge-plane/dil-service/
├── arf_dil/
│   ├── __init__.py
│   ├── server.py              # DIL服务的gRPC服务器入口
│   ├── main_loop.py           # 核心决策循环
│   ├── world_model.py         # 世界模型/状态管理
│   ├── bt_manager.py          # 行为树管理器
│   ├── policies/              # 策略库
│   │   └── navigation.py
│   └── clients/               # 调用其他ARF服务的gRPC客户端封装
│       └── acr_client.py
├── tests/
│   └── test_main_loop.py
├── configs/
│   └── default_behaviors.xml  # 行为树的XML定义文件
├── Dockerfile
├── requirements.txt
└── README.md
```

### 🧪 6.2 测试与验证策略



- **单元测试:** 对`world_model`、`policies`等纯逻辑模块进行单元测试。
- **集成测试:**
  - **模拟器测试:** 在`仿真模块`中，搭建一个标准测试场景。编写测试脚本，通过gRPC向DIL提交一个多步任务（如“找到红色方块并推到绿色区域”），验证任务能否被成功分解和执行。
  - **数据驱动测试:** 使用`DMS`的数据回放功能，向DIL注入一段真实的传感器数据，验证其决策逻辑是否符合预期。

------



## 🚀 7. 开发任务 (Getting Started)





#### **第一阶段：核心框架与数据融合 (Foundation & Fusion)**



- **任务1：实现DIL服务骨架**
  - **交付物:** 一个用Python实现的`DILService`，包含所有RPC方法的空实现。
- **任务2：实现数据订阅与世界模型**
  - **交付物:** DIL能够使用`Python SDK`从`DMS`订阅至少两种不同的感知数据（如目标列表、机器人位姿），并将其存储在内部的`WorldModel`对象中。
- **任务3：实现一个简单的“直通”决策流**
  - **交付物:** 一个最简单的逻辑：当`WorldModel`中检测到“人”时，调用`HAL`的`MotorActuatorService`让机器人底盘停止运动。



#### **第二阶段：任务编排与执行 (Orchestration & Execution)**



- **任务1：集成行为树引擎**
  - **交付物:** 集成`py_trees`库，实现一个可以加载和执行XML定义的行为树的`BTManager`。
- **任务2：开发第一批行为节点**
  - **交付物:** 开发至少3个可复用的行为节点：`IsObjectDetected` (Condition), `CallACRService` (Action), `CallHALService` (Action)。
- **任务3：实现第一个多步任务**
  - **交付物:** 编写一个行为树XML文件，实现“在场景中寻找一个特定物体”的任务。



#### **第三阶段：知识推理与高级决策 (Reasoning & Advanced Decision)**



- **任务1：集成LLM服务**
  - **交付物:** 实现一个`LLMAgent`，能够将自然语言指令发送给LLM服务，并解析返回的结构化子任务。
- **任务2：实现策略库**
  - **交付物:** 实现一个`PolicyManager`，可以根据名称加载不同的Python策略类。并实现第一个具体的策略（如一个简单的避障导航策略）。
- **任务3：任务规划与策略执行联动**
  - **交付物:** DIL能够接收一个高级指令（如“去厨房”），由`LLMAgent`分解为`MapsTo(kitchen)`，然后由`BTManager`执行，`MapsTo`节点再从`PolicyManager`中加载导航策略来完成移动。



#### **第四阶段：安全、鲁棒性与优化 (Safety, Robustness & Optimization)**



- **任务1：实现安全调度器**
  - **交付物:** 实现`SafetyScheduler`，能够根据模拟的风险信号，覆盖行为树的输出，并发送紧急停止指令。
- **任务2：集成真实端到端测试**
  - **交付物:** 在一个真实的机器人上，完整地运行第三阶段开发的“去厨房”任务，并提交测试报告。
- **任务3：性能分析与优化**
  - **交付物:** 分析整个决策链条的端到端延迟，并进行初步优化。



#### **第五阶段及以后：迈向认知代理 (Towards Cognitive Agency)**



*此部分为V1.1及后续版本规划，旨在实现更高阶的智能。*

- **任务5.1: 实现在线学习闭环**
  - **交付物:** 实现`在线学习管理器`。在一个完整的“自主失败 -> 遥操作修正 -> 数据记录 -> 在线微调”的端到端测试中，验证微调后的模型在同一任务上的成功率有显著提升。
- **任务5.2: 集成预测性世界模型**
  - **交付物:** 与算法团队协作，将一个预训练的“行人意图预测模型”作为`ACR`容器部署。DIL能够调用此模型，并在仿真环境中展示其在动态避障任务中的效果优于纯反应式策略。
- **任务5.3: 开发长期记忆原型**
  - **交付物:** 实现`长期记忆接口`，并开发一个家庭服务应用场景：用户可以告知机器人自己物品的存放位置，并在第二天通过自然语言查询，机器人能够根据记忆成功取回物品。
- **任务5.4: 完善模式管理器与人机协同**
  - **交付物:** 完整实现`DIL`内部的`模式管理器`和`失败检测器`，确保自主模式和遥操作模式之间可以无缝、可靠地切换。